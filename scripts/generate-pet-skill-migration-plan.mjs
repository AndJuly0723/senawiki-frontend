import { randomUUID } from 'node:crypto'
import { promises as fs } from 'node:fs'
import path from 'node:path'

const args = process.argv.slice(2)

const getArg = (name, fallback) => {
  const prefix = `--${name}=`
  const found = args.find((arg) => arg.startsWith(prefix))
  return found ? found.slice(prefix.length) : fallback
}

const bucket = getArg('bucket', 'senawiki-assets')
const skillsDir = getArg('skillsDir', 'public/images/petskill')
const outDir = getArg('outDir', 'scripts/output/pet-skill-migration')
const petsTable = getArg('petsTable', 'pets')
const idColumn = getArg('idColumn', 'id')
const prefix = getArg('prefix', 'pet-skills')

const extToMime = {
  '.jpg': 'image/jpeg',
  '.jpeg': 'image/jpeg',
  '.png': 'image/png',
  '.webp': 'image/webp',
  '.gif': 'image/gif',
}

const sqlEscape = (value) => String(value).replace(/'/g, "''")
const toPosix = (value) => value.split(path.sep).join('/')

const buildRows = async () => {
  const petDirs = await fs.readdir(skillsDir, { withFileTypes: true })
  const rows = []

  for (const dirEntry of petDirs) {
    if (!dirEntry.isDirectory()) continue
    const petId = dirEntry.name
    const absoluteDir = path.join(skillsDir, petId)
    const files = await fs.readdir(absoluteDir, { withFileTypes: true })

    for (const fileEntry of files) {
      if (!fileEntry.isFile()) continue
      const ext = path.extname(fileEntry.name).toLowerCase()
      const mimeType = extToMime[ext]
      if (!mimeType) continue

      const baseName = path.basename(fileEntry.name, ext).toLowerCase()
      if (baseName !== 'skill') continue

      const key = `${prefix}/${randomUUID()}${ext}`
      rows.push({
        petId,
        localPath: toPosix(path.join(absoluteDir, fileEntry.name)),
        key,
        mimeType,
      })
    }
  }

  return rows
}

const writeOutputs = async (rows) => {
  await fs.mkdir(outDir, { recursive: true })

  const manifest = {
    generatedAt: new Date().toISOString(),
    bucket,
    prefix,
    fileCount: rows.length,
    rows,
  }

  const uploadCommands = rows.map(
    (row) => `aws s3 cp "${row.localPath}" "s3://${bucket}/${row.key}" --content-type "${row.mimeType}"`,
  )

  const sqlLines = rows.map(
    (row) =>
      `UPDATE ${petsTable} SET skill_image='${sqlEscape(row.key)}' WHERE ${idColumn}='${sqlEscape(row.petId)}';`,
  )

  const sqlBody = [
    '-- generated by scripts/generate-pet-skill-migration-plan.mjs',
    'BEGIN;',
    ...sqlLines,
    'COMMIT;',
    '',
  ].join('\n')

  await Promise.all([
    fs.writeFile(path.join(outDir, 'manifest.json'), `${JSON.stringify(manifest, null, 2)}\n`, 'utf8'),
    fs.writeFile(path.join(outDir, 'upload.ps1'), `${uploadCommands.join('\n')}\n`, 'utf8'),
    fs.writeFile(
      path.join(outDir, 'upload.sh'),
      `#!/usr/bin/env bash\nset -euo pipefail\n\n${uploadCommands.join('\n')}\n`,
      'utf8',
    ),
    fs.writeFile(path.join(outDir, 'update-pet-skill-image-key.sql'), sqlBody, 'utf8'),
  ])
}

const main = async () => {
  const rows = await buildRows()
  await writeOutputs(rows)
  console.log(`Generated pet skill migration plan: ${rows.length} files`)
  console.log(`Output directory: ${outDir}`)
}

main().catch((error) => {
  console.error(error)
  process.exit(1)
})
